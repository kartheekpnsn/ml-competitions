{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic code for Machine learning competetions in Python\n",
    "---\n",
    "## Load libraries\n",
    "### Additional things\n",
    "1. Remove warnings\n",
    "2. Pandas maximum columns display = 1000\n",
    "3. Matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib as mpl\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.rcParams['figure.dpi'] = 500\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_missing(data):\n",
    "    return(data.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_incident_rate(data, target = 'target'):\n",
    "    if target in data.columns:\n",
    "        ## check target class\n",
    "        return(data[target].value_counts(normalize=True))\n",
    "    else:\n",
    "        print('No \"' + target + '\" column in your data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_train_test(train, test, target = 'target'):\n",
    "    if target in train.columns:\n",
    "        # # concatenate train and test to do pre-processing\n",
    "        train_target = train['target']\n",
    "        del train['target']\n",
    "        train['train_flag'] = 1\n",
    "        test['train_flag'] = 0\n",
    "        total_data = train.append(test, ignore_index = True)\n",
    "        return(total_data)\n",
    "    else:\n",
    "        print('No \"' + target + '\" column in your data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divide_train_test(data, target):\n",
    "    # # seperate the data back to train and test\n",
    "    train = data[data.train_flag == 1]\n",
    "    test = data[data.train_flag == 0]\n",
    "    del train['train_flag']\n",
    "    del test['train_flag']\n",
    "    train['target'] = target\n",
    "    return({'train' : train, 'test' : test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ind_dep_cols(columns, target = 'target', drop_cols = []):\n",
    "    feature_names = [x for x in columns if x not in ['target'] + drop_cols]\n",
    "    return({'independent' : feature_names, 'dependent' : target})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Train test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train, target, train_size = 0.7, stratify = target, random_state = 294056)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Modelling\n",
    "### Model 1 - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_f1(pred, dtrain):\n",
    "    label = dtrain.get_label()\n",
    "    fs = f1_score(label, pred, average = 'weighted')\n",
    "    return 'fscore', fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# default parameters\n",
    "params = {'objective':'binary:logistic',\n",
    "          'learning_rate': 0.05,\n",
    "          'reg_alpha' : 5.0,\n",
    "          'gamma' : 5.0,\n",
    "          'random_state': 294056,\n",
    "          'eval_metric' : 'auc',\n",
    "          # 'colsample_bytree': 0.7,\n",
    "          # 'subsample': 0.8,\n",
    "          # 'max_depth': 10,\n",
    "          # 'min_child_weight': 11,\n",
    "          # 'missing': -999\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=X_train[feature_names], label=y_train)\n",
    "dvalid = xgb.DMatrix(data=X_valid[feature_names], label=y_valid)\n",
    "dtest = xgb.DMatrix(data=test[feature_names])\n",
    "watchlist = [(dtrain, 'train'),(dvalid, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrounds = 1000\n",
    "early_stopping_rounds = 40\n",
    "clf1 = xgb.train(params, dtrain, nrounds, watchlist, maximize = True, verbose_eval = 20, early_stopping_rounds = early_stopping_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and check importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(clf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "imp_vals = clf1.get_fscore()\n",
    "total = sum(list(imp_vals.values()))\n",
    "imp_vals_fs = [(i/total) * 100 for i in imp_vals.values()]\n",
    "imp_vals = pd.DataFrame({'cols' : list(imp_vals.keys()), 'fscore' : imp_vals_fs})\n",
    "imp_vals\n",
    "# del imp_vals_fs\n",
    "imp_vals.sort_values(['fscore'], ascending=[0]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred1 = clf1.predict(dvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_f1(pred, data):\n",
    "    label = data.get_label()\n",
    "    pred = np.reshape(pred, (len(label), 4), 1)\n",
    "    pred = np.argmax(pred, axis = 1)\n",
    "    # print(label.shape)\n",
    "    fs = f1_score(label, pred, average = 'weighted')\n",
    "    return 'fscore', fs, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train[feature_names], y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid[feature_names], y_valid, reference = lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt', # gbdt\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'num_leaves': 50, # 50\n",
    "    'learning_rate': 0.05, # 0.05\n",
    "    'feature_fraction': 0.7, # 0.7\n",
    "    'bagging_fraction': 0.8, # 0.8\n",
    "    'bagging_freq': 5, # 5\n",
    "    'verbose': 0, # 0\n",
    "    'max_depth' : -1, # -1\n",
    "    # 'num_class' : 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf2 = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=3000,\n",
    "                valid_sets=[lgb_train, lgb_valid],\n",
    "                early_stopping_rounds = 40,\n",
    "                verbose_eval=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and check importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2 = clf2.predict(X_valid[feature_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Model 3 - Sklearn Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf3 = RandomForestClassifier(n_estimators = 500)\n",
    "clf4 = GradientBoostingClassifier(n_estimators = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_pred = cross_val_score(clf4, X_train[feature_names], y_train, cv = 10, scoring = 'roc_auc')\n",
    "print(cv_pred)\n",
    "print(\"Std AUC: \" + str(np.std(cv_pred)))\n",
    "print(\"MEAN AUC: \" + str(np.mean(cv_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf4.fit(X_train[feature_names], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred4 = clf4.predict(test[feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
