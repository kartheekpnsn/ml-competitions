{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HACKEREARTH: #6 - Predict the damange to the building\n",
    "- **Competition** : [here](https://www.hackerearth.com/challenge/competitive/machine-learning-challenge-6-1/machine-learning/predict-the-energy-used-612632a9-3f496e7f/)\n",
    "\n",
    "- **Leaderboard** : [here](https://www.hackerearth.com/challenge/competitive/machine-learning-challenge-6-1/leaderboard/)\n",
    "\n",
    "- **Data**        : [Download](https://he-s3.s3.amazonaws.com/media/hackathon/machine-learning-challenge-6-1/predict-the-energy-used-612632a9-3f496e7f/a490e594-6-Dataset.zip)\n",
    "\n",
    "```\n",
    "Opened At : Jun 16, 2018, 09:00 PM IST\n",
    "Closed At : Aug 15, 2018, 11:55 PM IST\n",
    "Rank      : 44\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "Determining the degree of damage that is done to buildings post an earthquake can help identify safe and unsafe buildings, thus avoiding death and injuries resulting from aftershocks. Leveraging the power of machine learning is one viable option that can potentially prevent massive loss of lives while simultaneously making rescue efforts easy and efficient. In this challenge we provide you with the before and after details of nearly one million buildings after an earthquake. The damage to a building is categorized in five grades. Each grade depicts the extent of damage done to a building post an earthquake. Given building details, your task is to build a model that can predict the extent of damage that has been done to a building after an earthquake. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Code\n",
    "### 1. Load libraries\n",
    "#### Additional things\n",
    "- Remove warnings\n",
    "- Pandas maximum columns display = 1000\n",
    "- Matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import glob\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/train.csv')\n",
    "building_structure = pd.read_csv('../data/Building_Structure.csv')\n",
    "building_ownership_use = pd.read_csv('../data/Building_Ownership_Use.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "building_structure.drop(['district_id', 'vdcmun_id'], axis = 1, inplace = True)\n",
    "building_ownership_use.drop(['district_id', 'vdcmun_id', 'ward_id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_structure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_ownership_use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.set_index('building_id').join(building_structure.set_index('building_id')).reset_index()\n",
    "data = data.set_index('building_id').join(building_ownership_use.set_index('building_id')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.set_index('building_id').join(building_structure.set_index('building_id')).reset_index()\n",
    "test = test.set_index('building_id').join(building_ownership_use.set_index('building_id')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del building_structure\n",
    "del building_ownership_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('../data/full_train.csv', index = False)\n",
    "test.to_csv('../data/full_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. EDA\n",
    "\n",
    "#### 4.1 Check for missing\n",
    "- has_repair_started has approximately 5% missing values in both train and test\n",
    "  - replace missing with 2 (treat differently)\n",
    "- count_families has 1 missing value in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['count_families'][data['count_families'].isnull()] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['has_repair_started'][data['has_repair_started'].isnull()] = 2\n",
    "test['has_repair_started'][test['has_repair_started'].isnull()] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create model data\n",
    "- Seperate Independent and Dependent data\n",
    "- Label encoding for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_cols = ['building_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "independent_cols = [x for x in data.columns if x not in ['damage_grade'] + drop_cols]\n",
    "target = 'damage_grade'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[independent_cols]\n",
    "y = np.array(data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array([int(value.split()[1]) for value in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = X.columns[X.dtypes == 'object']\n",
    "numeric_cols = X.columns[X.dtypes != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for column in categorical_cols:\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "    test[column] = le.fit_transform(test[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 6. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size = 0.7, stratify = y, random_state = 294056)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = DecisionTreeClassifier()\n",
    "cross_val_score(clf1, X, y, scoring = make_scorer(f1_score, average='weighted'), cv = 10)\n",
    "# array([0.72248245, 0.72073848, 0.7182898 , 0.71662196, 0.71920304, 0.72171188, 0.72030592, 0.71891392, 0.71888828, 0.71699247])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1.fit(X, y)\n",
    "dt_pred = clf1.predict(test.drop(['building_id'], axis = 1))\n",
    "dt_pred = ['Grade ' + str(pred) for pred in dt_pred]\n",
    "dt_sub = pd.DataFrame({'building_id' : test['building_id'], 'damage_grade' : dt_pred})\n",
    "dt_sub.to_csv('../submissions/dt_sub1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = RandomForestClassifier(n_estimators = 1500)\n",
    "cv_scores = cross_val_score(clf2, X, y, scoring = make_scorer(f1_score, average='weighted'), cv = 5)\n",
    "print(np.mean(cv_scores))\n",
    "# for 10 trees: array([0.75505873, 0.75331655, 0.75546319, 0.75023971, 0.75276322])\n",
    "# for 500 trees: array([0.77158428, 0.76935488, 0.77136891, 0.76922603, 0.76947412])\n",
    "# for 700 trees: array([0.771809  , 0.76984322, 0.77153816, 0.76925957, 0.76927937])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf2.fit(X, y)\n",
    "rf_pred = clf2.predict(test.drop(['building_id'], axis = 1))\n",
    "rf_pred = ['Grade ' + str(pred) for pred in rf_pred]\n",
    "rf_sub = pd.DataFrame({'building_id' : test['building_id'], 'damage_grade' : rf_pred})\n",
    "rf_sub.to_csv('../submissions/rf_sub3.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 6.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid, y_valid, reference = lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify your configurations as a dict# specify \n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_error',\n",
    "    'num_leaves': 50,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'max_depth' : -1,\n",
    "    'num_class' : 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lgb_f1(pred, data):\n",
    "    label = data.get_label()\n",
    "    pred = np.reshape(pred, (len(label), 5), 1)\n",
    "    pred = np.argmax(pred, axis = 1)\n",
    "    fs = f1_score(label, pred, average = 'weighted')\n",
    "    return 'fscore', fs, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf3 = lgb.train(params,\n",
    "            lgb_train,\n",
    "            num_boost_round=5000,\n",
    "            valid_sets=[lgb_train, lgb_valid],\n",
    "            early_stopping_rounds = 100,\n",
    "            verbose_eval=20,\n",
    "            feval = lgb_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_pred = ['Grade ' + str(pred + 1) for pred in np.argmax(clf3.predict(test.drop(['building_id'], axis = 1)), axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_sub = pd.DataFrame({'building_id': test['building_id'], 'damage_grade': lgb_pred})\n",
    "lgb_sub.to_csv('../submissions/lgb_sub2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
